---
title: "ESM Methods Comparison"
author: "Katy Dynarski"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Packages
library(here)
library(janitor)
library(readxl)
library(writexl)
library(viridis)
library(paletteer)
library(rms)
library(aqp)
library(cowplot)
library(lme4)
library(lmerTest)
library(broom.mixed)
library(multcomp)
library(ggeffects)
library(flextable)
library(tidyverse)

# Data
esm_all <- read.csv(here("data_processed", "esm_all.csv"))

# List of projects
projects <- esm_all %>% 
  distinct(project) %>% 
  pull()

# Make list of summary functions - useful for generating summary tables
sd_cv <- list(
  sd = ~round(sd(.x, na.rm = TRUE), 2),
  cv = ~round(((sd(.x, na.rm=TRUE) / mean(.x, na.rm=TRUE))* 100), 2)
)

# depth layer labels
std_depth_labels <- c(
  "1" = "0-10 cm",
  "2" = "10-30 cm",
  "3" = "30-50 cm",
  "4" = "50-75 cm",
  "5" = "75-100 cm"
)
```

# How does ESM choice influence total calculated SOC stocks?

## Compare calculated SOC stocks in different depth increments

Compare calculated 0-10 cm SOC stocks in all projects, gridded by method and colored by reference mass summary statistic. This will be the same for genetic horizon and standard depth increment data, so we can choose either to plot. Here we are just looking at data where reference masses were calculated separately for each individual DSP4SH project.

```{r boxplot of 0-10cm SOC stocks via different ESM methods}
esm_standard <- esm_all %>%
  filter(depth_increments == "standard", ref_data =="indv_project")

ggplot(esm_standard %>% filter(layer==1),
       aes(x=label, y=soc, fill=ref_stat)) +
  geom_boxplot() +
  facet_wrap(~method) +
  labs(y="SOC Stock (Mg/ha) in 0-10 cm") +
  scale_fill_paletteer_d("nationalparkcolors::Arches", name="Reference Mass") +
  theme_classic()
```

It's hard to read/interpret this because the projects have a lot of variability in SOC - plot them individually instead

```{r boxplot of 0-10 cm SOC stocks, gridded by project, echo=FALSE}
purrr::map(.x = projects, 
           .f = ~{
             esm_standard %>% 
               filter(layer == 1, project==.x) %>%
               ggplot(aes(x=label, y=soc, fill=ref_stat)) +
               geom_boxplot() +
               facet_wrap(~method) +
               labs(x="Management",
                    y="SOC Stock (Mg/ha) in 0-10 cm",
                    title=glue::glue(.x, " - 0-10 cm SOC Stocks")) +
               scale_fill_paletteer_d("nationalparkcolors::Arches", name="Reference Mass") +
               theme_classic() +
               theme(plot.title=element_text(hjust=0.5))

                                     })
```

Within each project, it appears that choice in SOC stock calculation method (ESM vs fixed depth) does result in different SOC stocks (we will test this statistically later on with a linear mixed model). For ESM calculations, choice in the maximum, mean, or minimum soil mass for a reference mass also seems to influence SOC stocks - the greater the reference soil mass used, the greater the calculated SOC stock in the 0-10 cm depth. Differences between management treatments appear consistent regardless of SOC stock calculation method.  

Calculate SOC stock totals for different depths (0-10cm, 0-30cm, and 0-100 cm):

```{r calculate SOC stock totals for different depth increments}
esm_standard_totals <- esm_standard %>%
  group_by(project, depth_increments, method_long, method, ref_stat, label, dsp_pedon_id) %>%
  summarize(soc_0to10 = sum(soc[apparent_depth=="0-10 cm"]),
            soc_0to30 = sum(soc[apparent_depth=="0-10 cm" | apparent_depth=="10-30 cm"]),
            soc_0to100 = sum(soc))

esm_standard_totals_longer <- esm_standard_totals %>%
  pivot_longer(cols=soc_0to10:soc_0to100,
               names_to = c(".value", "depth"),
               names_sep="_") %>%
  mutate(label=factor(label, levels=c("BAU", "SHM", "Ref")),
         depth=factor(depth, levels=c("0to10", "0to30", "0to100")))
```

Plot SOC stock totals via different methods and depth increments for each project:

```{r boxplots of SOC stock totals, different methods and depths, echo=FALSE}
stock_totals_plots <- purrr::map(.x = projects,
                                 .f = ~{
                                   esm_standard_totals_longer %>%
                                     filter(project==.x) %>%
                                     ggplot(aes(x=label, y=soc, fill=ref_stat)) +
                                     geom_boxplot() +
                                     facet_grid(depth ~ method, scales="free_y") +
                                     scale_fill_paletteer_d("nationalparkcolors::Arches", name="Reference Mass") +
                                     labs(title=glue::glue("Comparison of ESM Methods for \nCalcuating SOC Stock Totals - ", .x),
                                          y = "SOC Stock (Mg/ha)",
                                          x ="Management") +
                                     theme_classic() +
                                     theme(plot.title=element_text(hjust=0.5))

                                 })

stock_totals_plots
```

What we can tell from looking at the boxplots:

-   For most projects, using an ESM method (either ESM1 or ESM2) seems to yield a different SOC stock total than using fixed depth methods

-   ESM1 and ESM2 stocks do not appear different

-   It does seem to matter which reference mass is used - using the maximum reference mass tends to yield a higher SOC estimate than using the minimum (which makes sense mathematically)

-   The differences between methods seem muted when more depth is accounted for. There seem to be bigger differences between methods for 0-10 cm stocks than for 0-100 cm stocks

-   Using the minimum reference mass seems to minimize the spread of the ESM2 stock data (though that may just reflect the fact that the numbers are smaller using ESM2 and a smaller reference mass)

## Test effect of ESM calculation method on total SOC stocks via linear mixed models

```{r lme for effect of overall method on SOC stocks}
# Fixed effect is calculation method, random effect is project and label (to account for variation in SOC stocks by project and management)

# For 0-10 cm stocks
esm_std_0to10_lmer <- lmer(soc_0to10 ~ method_long + (1|project/label), data = esm_standard_totals)
summary(esm_std_0to10_lmer)
plot(esm_std_0to10_lmer)
qqnorm(resid(esm_std_0to10_lmer))
qqline(resid(esm_std_0to10_lmer))

# Is method significant overall?
drop1(lmer(soc_0to10 ~ method_long + (1|project/label), data = esm_standard_totals, REML=FALSE), test = "Chisq")

# Which methods result in significantly different SOC stocks?
summary(glht(esm_std_0to10_lmer, linfct = mcp(method_long = 'Tukey')))

# For 0-30 cm stocks
esm_std_0to30_lmer <- lmer(soc_0to30 ~ method_long + (1|project/label), data = esm_standard_totals)
summary(esm_std_0to30_lmer)
plot(esm_std_0to30_lmer)
qqnorm(resid(esm_std_0to30_lmer))
qqline(resid(esm_std_0to30_lmer))

# Is method significant overall?
drop1(lmer(soc_0to30 ~ method_long + (1|project/label), data = esm_standard_totals, REML=FALSE), test = "Chisq")

# Which methods result in significantly different SOC stocks?
summary(glht(esm_std_0to30_lmer, linfct = mcp(method_long = 'Tukey')))

esm_std_0to100_lmer <- lmer(soc_0to100 ~ method_long + (1|project/label), data = esm_standard_totals)
summary(esm_std_0to100_lmer)
plot(esm_std_0to100_lmer)
qqnorm(resid(esm_std_0to100_lmer))
qqline(resid(esm_std_0to100_lmer))

# Is method significant overall?
drop1(lmer(soc_0to100 ~ method_long + (1|project/label), data = esm_standard_totals, REML=FALSE), test = "Chisq")

# Which methods result in significantly different SOC stocks?
summary(glht(esm_std_0to100_lmer, linfct = mcp(method_long = 'Tukey')))

# Is ESM vs fixed depth important for 0-100 cm depth?
esm_std_0to100_lmer2 <- lmer(soc_0to100 ~ method + (1|project/label), data = esm_standard_totals)
summary(esm_std_0to100_lmer2)
drop1(lmer(soc_0to100 ~ method + (1|project/label), data = esm_standard_totals, REML=FALSE), test = "Chisq")
summary(glht(esm_std_0to100_lmer2, linfct = mcp(method = 'Tukey')))
```
Takeaways:

-   Overall, method (ESM vs FD, and reference soil choice) has a significant effect on SOC stocks (0-10 cm, 0-30 cm, and 0-100 cm).

-  For 0-10 cm and 0-30 cm depths, most methods result in significantly different SOC stocks. ESM-mean tends to be most comparable to fixed depth.

-   For 0-100 cm depth, there are fewer significant differences between methods. Fixed depth vs. ESM has fewer significant differences, but differences exist between ESM calculations using different reference masses.

-   Using a separate linear mixed model testing only effect on ESM method (not accounting for different reference mass choices) on 0-100 cm SOC stocks, there is no significant difference between ESM and fixed depth SOC stock calculations.

## Test influence of ESM method choice vs reference mass choice

Now that we know method of calculation matters (which we suspected before!), we can test if the style of ESM (classic vs cubic spline) matters more than the reference mass chosen:

```{r lme testing esm method vs reference stat}
esm_standard_totals_no_fd <- esm_standard_totals %>%
  filter(method!="fd")

# 0 to 10 cm
# Fit model
esm_std_0to10_no_fd_lmer <- lmer(soc_0to10 ~ method + ref_stat + (1|project/label), data = esm_standard_totals_no_fd)
summary(esm_std_0to10_no_fd_lmer)

# test significance of fixed effects
drop1(lmer(soc_0to10 ~ method + ref_stat + (1|project/label), data = esm_standard_totals_no_fd, REML=FALSE), test = "Chisq")

# 0-30 cm depth
esm_std_0to30_no_fd_lmer <- lmer(soc_0to30 ~ method + ref_stat + (1|project/label), data = esm_standard_totals_no_fd)
summary(esm_std_0to30_no_fd_lmer)

# test significance of fixed effects
drop1(lmer(soc_0to30 ~ method + ref_stat + (1|project/label), data = esm_standard_totals_no_fd, REML=FALSE), test = "Chisq")

# 0-100 cm depth
esm_std_0to100_no_fd_lmer <- lmer(soc_0to100 ~ method + ref_stat + (1|project/label), data = esm_standard_totals_no_fd)
summary(esm_std_0to100_no_fd_lmer)

# test significance of fixed effects
drop1(lmer(soc_0to100 ~ method + ref_stat + (1|project/label), data = esm_standard_totals_no_fd, REML=FALSE), test = "Chisq")
```

For all depths, we find no significant effect of classic vs. cubic spline, but a significant effect of which reference statistic is chosen. This makes sense - the reference mass chosen should affect the calculated SOC stocks. Nice that cubic spline and classic ESM methods appear comparable.

## How does choice in reference statistic influence total SOC stock error?

Since we don't know the "true" SOC stock, it's hard to know which reference statistic is the correct one to pick. One way to make this decision could be to select the reference statistic that reduces the error of the calculated SOC stocks. Visually this appears to be the minimum mass (and that would make sense mathematically), but we can verify. We will just use data calculated using standard depth increments.

```{r calculate sd and cv for different reference statistic methods}
# Only look at ESM2 data
esm2_std_totals <- esm_standard_totals_longer %>%
  filter(method=="esm2")

# Make one version grouped by project and treatment
esm2_std_totals_error_byproj <- esm2_std_totals %>%
  group_by(project, label, depth, ref_stat) %>%
  summarize(across(soc, sd_cv)) 

# Calculate mean CV for each depth and reference mass (CVs calculated for each project, treatment, depth, and reference mass, then averaged for each depth/reference mass combination)
flextable(esm2_std_totals_error_byproj %>%
  ungroup() %>%
  group_by(depth, ref_stat) %>%
  summarize(mean_cv = mean(soc_cv, na.rm=TRUE)))
```

I'm not really sure of the most robust/defensible way to compare error, BUT from this cursory inspection, error seems comparable between reference stat methods - the mean within-group (project/management) coefficient of variability is essentially the same for all methods in all depths.

I think that these results show that it is defensible to pick whatever ESM method makes sense - and using the minimum reference mass is a good idea, especially if you want to use deep cores - then you're not extrapolating to depths you haven't collected data from. 

## How does choice of depth increments influence total SOCK stocks?

Compare SOC stocks calculated for 0-10 cm and 0-100 cm when ESM calculations are done on a genetic horizon basis vs. standard depth increments basis. This *should* result in veyr similar results since the same data is used in both cases (just assigned differently to depth increments), but is a good check to ensure that assigning data to different depth increments doesn't introduce additional error.

```{r comparison of SOC stocks between genetic horizon and standard depth increments, echo=FALSE}
# Filter out genetic horizon data
esm_gen <- esm_all %>%
  filter(depth_increments == "genetic_hrz")

# Calculate 0-10 cm and 0-100 cm SOC stocks for genetic horizon data (can't get 0-30 cm SOC stocks because not all soils had a genetic horizon split here)
esm_gen_totals <- esm_gen %>%
  group_by(project, depth_increments, method_long, method, ref_stat, label, dsp_pedon_id) %>%
  summarize(soc_0to10 = sum(soc[apparent_depth=="0-10 cm"]),
            soc_0to100 = sum(soc))

# Pivot longer
esm_gen_totals_longer <- esm_gen_totals %>%
  pivot_longer(cols=soc_0to10:soc_0to100,
               names_to = c(".value", "depth"),
               names_sep="_") %>%
  mutate(label=factor(label, levels=c("BAU", "SHM", "Ref")),
         depth=factor(depth, levels=c("0to10", "0to100")))

# Join to standard depth increment data
esm_gen_std_totals <- rbind(esm_standard_totals_longer, esm_gen_totals_longer)

# Plot
purrr::map(.x = projects, .f= ~{
  ggplot(esm_gen_std_totals %>% filter(project == .x, depth!="0to30"), 
         aes(x=method_long, y=soc, fill=depth_increments)) +
    geom_boxplot() +
    facet_wrap(~depth, scales="free_y") +
    labs(x="SOC stock calculation method",
         y="SOC Stock (Mg/ha)",
         title=glue::glue("Influence of depth increment selection on \nSOC stock calculation - ", .x)) +
    scale_fill_paletteer_d("nationalparkcolors::Arches", name="Depth Increments") +
    theme_classic() +
    theme(plot.title=element_text(hjust=0.5),
          axis.text.x=element_text(angle=45, hjust=1))
})
```

# How does ESM method choice influence within-layer error?

## Influence of ESM method on soil depths used for calculations

One way to think about this is how the different ESM method choices influence the actual soil depths used to calculate the ESM SOC stocks for each depth increment. Method choices that result in extrapolation (e.g. use of depths that don't have actual samples) should probably be avoided.

Plot the actual depths used for ESM cubic spline calculations for all projects, comparing reference masses calculated separately for individual projects vs. the same reference mass being used for all projects:

```{r boxplot of actual depths used for ESM cubic spline calculations, echo=FALSE, fig.dim = c(11, 8.5)}
# Plot for all projects
purrr::map(.x = projects,
           .f = ~{
             cubic <- esm_all %>% 
               filter(depth_increments=="standard", method=="esm2", project==.x) %>%
               ggplot(aes(x=ref_stat, y=depth, fill=ref_data)) +
               geom_boxplot() +
               facet_wrap(~layer, scales="free_y", labeller=labeller(layer=std_depth_labels)) +
               labs(x="Reference Summary Statistic",
                    y="Actual bottom depth used for ESM calculations", 
                    title="Cubic spline ESM") +
               scale_fill_paletteer_d("nationalparkcolors::Arches", 
                                      name="Reference Data Source", labels=c("Entire DSP4SH dataset", "Individual project")) +
               theme_classic() +
               theme(plot.title=element_text(hjust=0.5))
             
             classic <- esm_all %>% 
               filter(depth_increments=="standard", method=="esm1", project==.x) %>%
               ggplot(aes(x=ref_stat, y=depth, fill=ref_data)) +
               geom_boxplot() +
               facet_wrap(~layer, scales="free_y", labeller=labeller(layer=std_depth_labels)) +
               labs(x="Reference Summary Statistic",
                    y="Actual bottom depth used for ESM calculations", 
                    title="Classic (non-modeled) ESM") +
               scale_fill_paletteer_d("nationalparkcolors::Arches", 
                                      name="Reference Data Source", labels=c("Entire DSP4SH dataset", "Individual project")) +
               theme_classic() +
               theme(plot.title=element_text(hjust=0.5))
             
             plot_row <- plot_grid(classic + theme(legend.position="none"), 
                                   cubic, 
                                   nrow=1, labels=c("A", "B"), rel_widths=c(1, 1.3))
             
             title <- ggdraw() +
                     draw_label(glue::glue("Influence of Reference Mass Choice on Soil Depths Used for ESM Calculations - ", .x))
             
             plot_grid(title, plot_row, ncol=1, rel_heights = c(0.1, 1))

           })
```

It looks like we get some crazy depths for some projects - e.g. looks like points down to -400 cm are used to calculated Kansas State SOC stocks in the 75-100 cm depth increment. Isolate the very deep points to see where that's coming from:

```{r isolate unrealistically deep points}
deep <- esm_all %>%
  filter(depth < -220) %>%
  distinct(dsp_pedon_id, ref_data, ref_stat) 
flextable(deep)
```

Funky depths only happen when using the same reference mass for the entire dataset, and almost always when using the maximum soil mass as a reference. 

Takeaway: *using the same reference mass for all DSP4SH data results in nonsensical calculations!! Reference masses should be calculated in a way where all soils are compared to an appropriate reference.*

## Influence of depth increments used on within-layer error

Another thing to check is that re-configuring the soil data into standard depth increments doesn't introduce additional error into the within-layer SOC stock calculations. We can check this by comparing the within-layer error for genetic horizon vs. standard depth increments calculations.

Calculate and plot within-layer coefficient of variation for each project/management group, using different SOC stock calculation methods and depth increments:

```{r calculate and plot within-layer CV}
# calculate CV for each layer within each project/management group
depth_comp_error <- esm_all %>%
  filter(ref_data=="indv_project") %>%
  group_by(project, label, method_long, depth_increments, layer) %>%
  summarize(layer_cv = round(((sd(soc, na.rm=TRUE) / mean(soc, na.rm=TRUE))* 100), 2))

# Plot CVs
ggplot(depth_comp_error, aes(y=layer_cv, x=method_long, fill=depth_increments)) +
  geom_boxplot() +
  facet_grid(project~layer, scales="free_y") +
  labs(x="SOC stock calculation method", y="Layer Coefficient of Variation") +
  scale_fill_paletteer_d("nationalparkcolors::Arches", name="Depth Increments") +
  theme_classic()
```

This figure is small and hard to interpret but overall I am pretty sure it shows that the within-layer CVs are pretty much the same whether SOC stocks are calculated on a standard depth increments basis or a genetic horizon basis.

Try pulling out just one project to be able to see better:

```{r plot CV vs. calculation method and depth increment for Illinois project only, echo=FALSE}
ggplot(depth_comp_error %>% filter(project=="Illinois"), aes(y=layer_cv, x=method_long, fill=depth_increments)) +
  geom_boxplot() +
  facet_wrap(~layer, scales="free_y") +
  labs(x="SOC stock calculation method", y="Layer Coefficient of Variation", title="Illinois") +
  scale_fill_paletteer_d("nationalparkcolors::Arches", name="Depth Increments") +
  theme_classic() +
  theme(axis.text.x=element_text(angle=45, hjust=1))
```

Perhaps there is slightly greater error in the ESM2 method vs ESM1 method, especially in greater depths. We can better explore patterns in CV using a linear mixed model.

```{r lme for within-layer cv vs calculation method and depth increment}
depth_comp_lmer <- lmer(layer_cv ~ method_long + depth_increments + (1|project/label/layer), data = depth_comp_error)
summary(depth_comp_lmer)
plot(depth_comp_lmer)
qqnorm(resid(depth_comp_lmer))
qqline(resid(depth_comp_lmer))

# Is method or depth increment significant overall?
drop1(lmer(layer_cv ~ method_long + depth_increments + (1|project/label/layer), data = depth_comp_error, REML=FALSE), test = "Chisq")

# should be able to figure out which method results in least within-layer error????
summary(glht(depth_comp_lmer, linfct = mcp(method_long = 'Tukey')))

# Plot predictions of within-layer error for each method
depth_comp_pred <- ggpredict(depth_comp_lmer, terms = c("method_long"))

ggplot(depth_comp_pred , aes(x=x, y=predicted)) +
  geom_point() +
  geom_errorbar(aes(x=x, ymin=conf.low, ymax=conf.high)) +
  labs(x="SOC stock calculation method", y="Predicted within-layer CV") +
  theme_classic()
```

Takeaways:

-   Calculation method (ESM vs FD, and choice in reference soil) significantly influences within-layer error, but depth increment choice does not. 

-   Interestingly, there seems to be greater error when ESM2 (cubic spline) is used with maximum reference soil - maybe because of the extrapolation required? 

-   ESM2-max results in significantly greater error than: ESM1-max, ESM1-mean, ESM1-min, ESM2-mean, ESM2-min, and fixed depth. 

-   All other methods result in comparable error to each other.

# How does ESM method choice influence observed differences between management treatments?

We will focus on standard depth increments here because we know there is no significant difference in SOC stocks based on depth increment method selection, and standard depth increments are easier to compare between projects.

First, we will examine how ESM method selection influences our ability to detect management effects in total SOC stocks.

Run linear mixed models for each method/depth combination and extract significance:

```{r lme for management effect on total SOC stocks in each method/depth combination}
# Run linear mixed model
esm_group_comp <- esm_standard_totals_longer %>%
  group_by(method_long, depth) %>%
  nest() %>%
  mutate(lmer = map(data, ~lmer(soc ~ label + (1|project), data = .x)),
  drop1 = map(data, .f = ~{
    drop1(lmer(soc ~ label + (1|project), REML=FALSE, data = .x))
    }),
  tidy_lmer = map(lmer, broom.mixed::tidy),
  tidy_drop = map(drop1, broom.mixed::tidy)) %>%
  select(method_long, depth, tidy_lmer, tidy_drop) %>%
  unnest(cols=c(tidy_lmer, tidy_drop), names_sep="_") %>%
  mutate(sig = case_when(tidy_drop_p.value < 0.05 ~ "significant",
                         tidy_drop_p.value > 0.05 ~ "not_significant"))

# Extract non-significant methods/depths
total_not_sig <- esm_group_comp %>%
  filter(sig=="not_significant") %>%
  distinct(method_long, depth, sig)

flextable(total_not_sig)
```

All methods detect significant between-group differences in all depths (0-10 cm, 0-30 cm, and 0-100 cm).

We can also examine how ESM method selection influences our ability to detect management effects in SOC stocks within specific layers.

Run linear mixed models for each method/layer combination and extract significance:

```{r lme for management effect on layer SOC stocks in each method/depth combination, warnings=FALSE}
# Run linear mixed model and extract significance
esm_layer_group_comp <- esm_standard %>%
  group_by(method_long, layer) %>%
  nest() %>%
  mutate(lmer = map(data, ~lmer(soc ~ label + (1|project), data = .x)),
         drop1 = map(data, .f = ~{
           drop1(lmer(soc ~ label + (1|project), REML=FALSE, data = .x))
         }),
         tidy_lmer = map(lmer, broom.mixed::tidy),
         tidy_drop = map(drop1, broom.mixed::tidy)) %>%
  select(method_long, layer, tidy_lmer, tidy_drop) %>%
  unnest(cols=c(tidy_lmer, tidy_drop), names_sep="_") %>%
  mutate(sig = case_when(tidy_drop_p.value < 0.05 ~ "significant",
                         tidy_drop_p.value > 0.05 ~ "not_significant"))

# Extract non-significant methods/layers
layer_not_sig <- esm_layer_group_comp %>%
  filter(sig=="not_significant") %>%
  distinct(method_long, layer, sig) %>%
  arrange(layer)

flextable(layer_not_sig)
```

Takeaways:

-   all methods find significant effects of management in 0-10 cm, 10-30 cm, and 30-50 cm layers

-   about half the calculation approaches find *no* significant management effect in 50-75 cm (ESM1 mean and max, ESM2 mean and max). All ESM min methods and fixed depth methods find significant management effects in 50-75 cm.

-   no calculation approaches find a significant management effect 75-100 cm layers

# Broad conclusions
-   Using ESM vs. fixed depth to calculated total SOC stocks results in significantly different calculated SOC stocks in shallow soils (0-10 cm and 0-30 cm). 

-   There is no significant difference between ESM vs. fixed depth SOC stocks for 0-100 cm. If you have enough depth, total stock is not influenced by calculation method.

-   Choice in classic vs. cubic spline ESM method does not strongly influence calculated SOC stocks for any depths

-   Cubic spline my be preferable simply because it is used more widely in the literature.

-   The minimum soil mass for a group seems to be the best choice for a reference soil mass. This requires less extrapolation in deeper parts of the soil profile, provides a more conservative estimate of SOC stocks, and results in less within-layer error when using ESM cubic spline method.

-   All ESM methods seemed equally able to distinguish patterns in SOC stocks between management treatments.

-   Separate reference masses should be calculated and used for groups of comparable soils. One single reference mass should not be used when investigating diverse soils with different textures/bulk density. Using one reference mass for the entire DSP4SH dataset resulted in significant extrapolation to calculate deeper SOC stocks for some soils, and very shallow soils to calculated 0-10 cm SOC stocks in other soils (e.g. calculating 0-10 cm stocks based on 0-4 cm data for some projects).

-   Need to be clear when reporting what choices were made and why, and what reference masses were used for what groups. It is hard to compare different soils to each other when ESM calculations use different reference masses. To compare different soils to each other, it may be preferable to collect samples to a greater depth and calculate total SOC stocks on a fixed-depth basis. 
